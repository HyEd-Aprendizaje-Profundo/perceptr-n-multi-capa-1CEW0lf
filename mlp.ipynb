{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfc33a8",
   "metadata": {},
   "source": [
    "# Práctica 1: Perceptrón multicapa.\n",
    "\n",
    "Tu jefe pidió a RH que recolectara datos de desempeño de tus compañeros, los resultados se almacenaron en un csv. El punto critico de estos datos es la satisfacción del empleado, entonces ¿Podremos estimar la satisfacción de los empleados con los datos recabados?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffe3db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tensorflow\\__init__.py:40\u001b[39m\n\u001b[32m     37\u001b[39m _os.environ.setdefault(\u001b[33m\"\u001b[39m\u001b[33mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "df = pd.read_csv('Extended_Employee_Performance_and_Productivity_Data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las columnas numéricas\n",
    "numeric_columns = df.select_dtypes(include=['number']).drop('Employee_ID',axis=1)\n",
    "\n",
    "\n",
    "# Si numeric_columns es un Index, conviértelo a lista\n",
    "cols = list(numeric_columns)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cols), figsize=(5 * len(cols), 4))\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    axes[i].hist(df[col], bins=20, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265314b",
   "metadata": {},
   "source": [
    "**Problemas**, tenemos distribuciones con picos, esos nos indica categorías. Por otro lado, tenemos variables con \"valles\" en su distribución (distribuciones multimodales) por lo que resultaría óptimo aplicar técnicas de feature engeneering. Por último tenemos distribuciones uniformes, por lo que cada una requeriría un procesamiento indivudual, hagamos la vista gorda e intentemos ajustar un MLP con estos datos, solo estandaricemos nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40920f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Implementación de Red:\n",
    "\n",
    "To**memos los datos numéricos como nuestra variable X, y la variable objetivo como ***'Employee_Satisfaction_Score'***.\n",
    "- **Actividad 1**: Para todos los strings ``'@modif@'`` que aparescan en el siguiente bloque de código cámbialos para que el código funcione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd081ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numeric_columns.drop('Employee_Satisfaction_Score', axis=1)\n",
    "y = numeric_columns['Employee_Satisfaction_Score']\n",
    "\n",
    "y = y.apply(lambda x: round(x) - 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standar = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standar, y, test_size=0.33, random_state=42)\n",
    "\n",
    "y_onehot_train = tf.keras.utils.to_categorical(y_train, 5)\n",
    "y_onehot_test = tf.keras.utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920d085",
   "metadata": {},
   "source": [
    "- **Actividad 2:** Implementa 3 arquitecturas de MLP, cada una con su propio nombre, cambiando la estructura de dichas arquitecturas (capas, neuronas por capa, función de activación, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Simple\n",
    "model1 = models.Sequential(name=\"MLP_simple\")\n",
    "model1.add(layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model1.add(layers.Dense(16, activation='relu'))\n",
    "model1.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# Modelo 2: Medio con dropout\n",
    "model2 = models.Sequential(name=\"MLP_dropout\")\n",
    "model2.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model2.add(layers.Dropout(0.3))\n",
    "model2.add(layers.Dense(32, activation='relu'))\n",
    "model2.add(layers.Dense(16, activation='relu'))\n",
    "model2.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# Modelo 3: Profundo\n",
    "model3 = models.Sequential(name=\"MLP_deep\")\n",
    "model3.add(layers.Dense(128, activation='tanh', input_shape=(X_train.shape[1],)))\n",
    "model3.add(layers.Dense(64, activation='tanh'))\n",
    "model3.add(layers.Dense(32, activation='relu'))\n",
    "model3.add(layers.Dense(16, activation='relu'))\n",
    "model3.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8c585",
   "metadata": {},
   "source": [
    "- **Actividad 3:** Compila y ajusta tus tres modelos con sus respectivos hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08db50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuración común\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "for model in [model1, model2, model3]:\n",
    "    print(f\"\\nEntrenando {model.name} ...\")\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_onehot_train,\n",
    "                        epochs=30,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_test, y_onehot_test),\n",
    "                        verbose=1)\n",
    "    \n",
    "    # Evaluación final\n",
    "    loss, acc = model.evaluate(X_test, y_onehot_test, verbose=0)\n",
    "    print(f\"Modelo {model.name} → Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c5202",
   "metadata": {},
   "source": [
    "- **Actividad 4:** Sube tus cambios al repositorio, envía el link de tu repositorio a la actividad 2 de tu checkpoint 2 y contesta las preguntas de dicha actividad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcaa1d",
   "metadata": {},
   "source": [
    "Si los datos son moderadamente grandes y complejos, yo me quedaría con MLP_dropout."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
